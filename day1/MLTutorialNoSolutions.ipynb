{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75dba511",
   "metadata": {},
   "source": [
    "# Tutorial for Introduction to ML Lecture\n",
    "\n",
    "version 0.1, September 2023\n",
    "\n",
    "Bryan Scott, CIERA/Northwestern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c6b0f",
   "metadata": {},
   "source": [
    "## Problem 1: Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07842041",
   "metadata": {},
   "source": [
    "A good starting point for Machine Learning is the Bayes classifier. The basic idea is to assign the most probable label to each data point using Bayes theorem, we take:\n",
    "\n",
    "$$\n",
    "p(y | x_n) \\propto p(y)p(x_i, ..., x_n | y)\n",
    "$$\n",
    "\n",
    "where y is a label for a data point and the $x_n$ are the features of the data that we want to use to classify each data point. A $\\textit{Naive} Bayes$ classifier makes an important simplifying assumptions that gives it the name - it assumes that the conditional probabilities are independent, $p(x_i, ..., x_n | y) = p(x_i|y)... p(x_n | y)$. That is, the probability of observing any individual feature doesn't depend on any of the other features. Our task is to construct this classifier from a set of examples we've observed previously and compare it to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40084db8",
   "metadata": {},
   "source": [
    "### Part 0: Load and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1d0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11443882",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_data = pd.read_csv('simulated_extragalactic_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e543f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_data[0:1000].to_csv('session_19_DC2_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fa6dd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsst_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1000bb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flux_g</th>\n",
       "      <th>flux_i</th>\n",
       "      <th>flux_r</th>\n",
       "      <th>flux_u</th>\n",
       "      <th>flux_y</th>\n",
       "      <th>flux_z</th>\n",
       "      <th>truth_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48682</th>\n",
       "      <td>11567264019</td>\n",
       "      <td>40.96230</td>\n",
       "      <td>36.2869</td>\n",
       "      <td>37.3803</td>\n",
       "      <td>42.79600</td>\n",
       "      <td>58.9711</td>\n",
       "      <td>40.2802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40607</th>\n",
       "      <td>11690845043</td>\n",
       "      <td>357.10800</td>\n",
       "      <td>571.4560</td>\n",
       "      <td>471.1240</td>\n",
       "      <td>484.44300</td>\n",
       "      <td>1199.9800</td>\n",
       "      <td>1002.8600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22854</th>\n",
       "      <td>11631772147</td>\n",
       "      <td>15.59330</td>\n",
       "      <td>14.6773</td>\n",
       "      <td>14.6509</td>\n",
       "      <td>15.88500</td>\n",
       "      <td>17.0612</td>\n",
       "      <td>14.5978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7554</th>\n",
       "      <td>11581148087</td>\n",
       "      <td>51.71180</td>\n",
       "      <td>64.1272</td>\n",
       "      <td>69.5459</td>\n",
       "      <td>22.81470</td>\n",
       "      <td>66.9363</td>\n",
       "      <td>58.9267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28188</th>\n",
       "      <td>11631115337</td>\n",
       "      <td>46.70340</td>\n",
       "      <td>42.7023</td>\n",
       "      <td>42.6977</td>\n",
       "      <td>48.35350</td>\n",
       "      <td>58.1880</td>\n",
       "      <td>42.2114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36892</th>\n",
       "      <td>11700048639</td>\n",
       "      <td>12.46040</td>\n",
       "      <td>13.9937</td>\n",
       "      <td>12.1656</td>\n",
       "      <td>6.85085</td>\n",
       "      <td>19.1662</td>\n",
       "      <td>17.1776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14582</th>\n",
       "      <td>11562625549</td>\n",
       "      <td>31.56970</td>\n",
       "      <td>96.4406</td>\n",
       "      <td>75.8143</td>\n",
       "      <td>11.79810</td>\n",
       "      <td>123.7010</td>\n",
       "      <td>111.2390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23836</th>\n",
       "      <td>11627559538</td>\n",
       "      <td>503.87300</td>\n",
       "      <td>942.4960</td>\n",
       "      <td>635.2230</td>\n",
       "      <td>588.65200</td>\n",
       "      <td>1740.1700</td>\n",
       "      <td>1526.6400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49128</th>\n",
       "      <td>11565382553</td>\n",
       "      <td>8.78313</td>\n",
       "      <td>15.1979</td>\n",
       "      <td>10.5897</td>\n",
       "      <td>8.62231</td>\n",
       "      <td>29.4473</td>\n",
       "      <td>27.0750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34352</th>\n",
       "      <td>11687872623</td>\n",
       "      <td>3.73018</td>\n",
       "      <td>21.3478</td>\n",
       "      <td>12.7027</td>\n",
       "      <td>0.89436</td>\n",
       "      <td>32.5717</td>\n",
       "      <td>27.6100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id     flux_g    flux_i    flux_r     flux_u     flux_y  \\\n",
       "48682  11567264019   40.96230   36.2869   37.3803   42.79600    58.9711   \n",
       "40607  11690845043  357.10800  571.4560  471.1240  484.44300  1199.9800   \n",
       "22854  11631772147   15.59330   14.6773   14.6509   15.88500    17.0612   \n",
       "7554   11581148087   51.71180   64.1272   69.5459   22.81470    66.9363   \n",
       "28188  11631115337   46.70340   42.7023   42.6977   48.35350    58.1880   \n",
       "...            ...        ...       ...       ...        ...        ...   \n",
       "36892  11700048639   12.46040   13.9937   12.1656    6.85085    19.1662   \n",
       "14582  11562625549   31.56970   96.4406   75.8143   11.79810   123.7010   \n",
       "23836  11627559538  503.87300  942.4960  635.2230  588.65200  1740.1700   \n",
       "49128  11565382553    8.78313   15.1979   10.5897    8.62231    29.4473   \n",
       "34352  11687872623    3.73018   21.3478   12.7027    0.89436    32.5717   \n",
       "\n",
       "          flux_z  truth_type  \n",
       "48682    40.2802           1  \n",
       "40607  1002.8600           1  \n",
       "22854    14.5978           1  \n",
       "7554     58.9267           1  \n",
       "28188    42.2114           1  \n",
       "...          ...         ...  \n",
       "36892    17.1776           1  \n",
       "14582   111.2390           1  \n",
       "23836  1526.6400           1  \n",
       "49128    27.0750           1  \n",
       "34352    27.6100           1  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsst_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c682ccc",
   "metadata": {},
   "source": [
    "### Loading and splitting the data. \n",
    "\n",
    "Read in the data, then start by selecting the id, fluxes, and object truth type in the lsst data file you've been provided. \n",
    "\n",
    "Once you have selected those, randomly split the data into two arrays, one containing 80% of the data, and a second array containing 20% of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "94094b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_data = pd.read_csv('session_19_DC2_subset.csv').reset_index() #path to your data\n",
    "\n",
    "col_to_classify = ['id','flux_g','flux_i','flux_r','flux_u','flux_y','flux_z','truth_type']\n",
    "\n",
    "lsst_data_to_classify = lsst_data.loc[:,col_to_classify]\n",
    "N_data_to_classify = lsst_data_to_classify.shape[0]\n",
    "random_data = np.sort(np.random.choice(N_data_to_classify, int(N_data_to_classify*0.2), replace=False))\n",
    "\n",
    "train_data = lsst_data_to_classify.drop(random_data).reset_index(drop=True)\n",
    "test_data = lsst_data_to_classify.loc[random_data].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ccc9a1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2  16  27  33  34  38  43  48  49  50  51  56  68  71  73  77  80  83\n",
      "  87  93  94  99 100 104 108 110 121 133 135 155 156 159 163 165 167 171\n",
      " 173 184 190 192 196 199 204 209 211 215 224 242 270 274 276 282 286 289\n",
      " 300 306 308 310 314 319 320 322 325 326 327 329 331 333 339 353 355 356\n",
      " 368 381 385 387 388 398 403 407 415 418 427 431 432 433 434 441 447 454\n",
      " 455 456 459 460 462 467 477 494 500 501 518 520 530 532 535 546 551 553\n",
      " 560 561 567 568 572 578 583 585 588 589 595 607 610 612 620 621 626 628\n",
      " 632 635 640 642 644 650 652 656 665 667 671 673 692 700 703 704 724 726\n",
      " 730 742 744 752 754 770 775 792 797 798 802 805 807 809 813 818 822 823\n",
      " 830 831 835 836 838 845 849 861 863 871 881 883 885 891 898 903 904 908\n",
      " 913 915 920 921 927 929 935 939 948 950 952 954 967 972 978 979 980 982\n",
      " 991 999]\n"
     ]
    }
   ],
   "source": [
    "print(random_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bad63cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flux_g</th>\n",
       "      <th>flux_i</th>\n",
       "      <th>flux_r</th>\n",
       "      <th>flux_u</th>\n",
       "      <th>flux_y</th>\n",
       "      <th>flux_z</th>\n",
       "      <th>truth_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11631772147</td>\n",
       "      <td>15.59330</td>\n",
       "      <td>14.6773</td>\n",
       "      <td>14.65090</td>\n",
       "      <td>15.88500</td>\n",
       "      <td>17.0612</td>\n",
       "      <td>14.5978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11565452667</td>\n",
       "      <td>27.71430</td>\n",
       "      <td>26.5303</td>\n",
       "      <td>25.52000</td>\n",
       "      <td>30.37460</td>\n",
       "      <td>37.5289</td>\n",
       "      <td>38.3631</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40745568334</td>\n",
       "      <td>65544.80000</td>\n",
       "      <td>92359.0000</td>\n",
       "      <td>84819.30000</td>\n",
       "      <td>28672.20000</td>\n",
       "      <td>94089.5000</td>\n",
       "      <td>93977.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11639300481</td>\n",
       "      <td>146.39600</td>\n",
       "      <td>109.8540</td>\n",
       "      <td>129.27900</td>\n",
       "      <td>94.26480</td>\n",
       "      <td>136.1850</td>\n",
       "      <td>125.9980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11568919652</td>\n",
       "      <td>11.59090</td>\n",
       "      <td>13.2037</td>\n",
       "      <td>10.40450</td>\n",
       "      <td>11.27840</td>\n",
       "      <td>22.1336</td>\n",
       "      <td>14.2701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>11567862080</td>\n",
       "      <td>8.48342</td>\n",
       "      <td>11.6592</td>\n",
       "      <td>9.07956</td>\n",
       "      <td>8.58720</td>\n",
       "      <td>26.3974</td>\n",
       "      <td>14.5710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>11575651179</td>\n",
       "      <td>9.28551</td>\n",
       "      <td>12.8492</td>\n",
       "      <td>11.75760</td>\n",
       "      <td>3.42997</td>\n",
       "      <td>18.5936</td>\n",
       "      <td>15.7811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>11575481781</td>\n",
       "      <td>15.27300</td>\n",
       "      <td>15.5485</td>\n",
       "      <td>14.85870</td>\n",
       "      <td>10.42210</td>\n",
       "      <td>18.3602</td>\n",
       "      <td>17.4043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>11626280998</td>\n",
       "      <td>5.20117</td>\n",
       "      <td>22.9789</td>\n",
       "      <td>10.79200</td>\n",
       "      <td>3.24677</td>\n",
       "      <td>27.9421</td>\n",
       "      <td>25.8164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>11687872623</td>\n",
       "      <td>3.73018</td>\n",
       "      <td>21.3478</td>\n",
       "      <td>12.70270</td>\n",
       "      <td>0.89436</td>\n",
       "      <td>32.5717</td>\n",
       "      <td>27.6100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       flux_g      flux_i       flux_r       flux_u  \\\n",
       "0    11631772147     15.59330     14.6773     14.65090     15.88500   \n",
       "1    11565452667     27.71430     26.5303     25.52000     30.37460   \n",
       "2    40745568334  65544.80000  92359.0000  84819.30000  28672.20000   \n",
       "3    11639300481    146.39600    109.8540    129.27900     94.26480   \n",
       "4    11568919652     11.59090     13.2037     10.40450     11.27840   \n",
       "..           ...          ...         ...          ...          ...   \n",
       "195  11567862080      8.48342     11.6592      9.07956      8.58720   \n",
       "196  11575651179      9.28551     12.8492     11.75760      3.42997   \n",
       "197  11575481781     15.27300     15.5485     14.85870     10.42210   \n",
       "198  11626280998      5.20117     22.9789     10.79200      3.24677   \n",
       "199  11687872623      3.73018     21.3478     12.70270      0.89436   \n",
       "\n",
       "         flux_y      flux_z  truth_type  \n",
       "0       17.0612     14.5978           1  \n",
       "1       37.5289     38.3631           1  \n",
       "2    94089.5000  93977.1000           2  \n",
       "3      136.1850    125.9980           1  \n",
       "4       22.1336     14.2701           1  \n",
       "..          ...         ...         ...  \n",
       "195     26.3974     14.5710           1  \n",
       "196     18.5936     15.7811           1  \n",
       "197     18.3602     17.4043           1  \n",
       "198     27.9421     25.8164           1  \n",
       "199     32.5717     27.6100           1  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca3c49af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flux_g</th>\n",
       "      <th>flux_i</th>\n",
       "      <th>flux_r</th>\n",
       "      <th>flux_u</th>\n",
       "      <th>flux_y</th>\n",
       "      <th>flux_z</th>\n",
       "      <th>truth_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11567264019</td>\n",
       "      <td>40.96230</td>\n",
       "      <td>36.2869</td>\n",
       "      <td>37.3803</td>\n",
       "      <td>42.79600</td>\n",
       "      <td>58.9711</td>\n",
       "      <td>40.2802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11690845043</td>\n",
       "      <td>357.10800</td>\n",
       "      <td>571.4560</td>\n",
       "      <td>471.1240</td>\n",
       "      <td>484.44300</td>\n",
       "      <td>1199.9800</td>\n",
       "      <td>1002.8600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11581148087</td>\n",
       "      <td>51.71180</td>\n",
       "      <td>64.1272</td>\n",
       "      <td>69.5459</td>\n",
       "      <td>22.81470</td>\n",
       "      <td>66.9363</td>\n",
       "      <td>58.9267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11631115337</td>\n",
       "      <td>46.70340</td>\n",
       "      <td>42.7023</td>\n",
       "      <td>42.6977</td>\n",
       "      <td>48.35350</td>\n",
       "      <td>58.1880</td>\n",
       "      <td>42.2114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11690275081</td>\n",
       "      <td>118.30800</td>\n",
       "      <td>373.8760</td>\n",
       "      <td>211.8320</td>\n",
       "      <td>120.56900</td>\n",
       "      <td>959.9060</td>\n",
       "      <td>784.7030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>11694913248</td>\n",
       "      <td>68.07290</td>\n",
       "      <td>74.1691</td>\n",
       "      <td>58.9424</td>\n",
       "      <td>50.73660</td>\n",
       "      <td>94.5738</td>\n",
       "      <td>86.5480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>11700048639</td>\n",
       "      <td>12.46040</td>\n",
       "      <td>13.9937</td>\n",
       "      <td>12.1656</td>\n",
       "      <td>6.85085</td>\n",
       "      <td>19.1662</td>\n",
       "      <td>17.1776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>11562625549</td>\n",
       "      <td>31.56970</td>\n",
       "      <td>96.4406</td>\n",
       "      <td>75.8143</td>\n",
       "      <td>11.79810</td>\n",
       "      <td>123.7010</td>\n",
       "      <td>111.2390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>11627559538</td>\n",
       "      <td>503.87300</td>\n",
       "      <td>942.4960</td>\n",
       "      <td>635.2230</td>\n",
       "      <td>588.65200</td>\n",
       "      <td>1740.1700</td>\n",
       "      <td>1526.6400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>11565382553</td>\n",
       "      <td>8.78313</td>\n",
       "      <td>15.1979</td>\n",
       "      <td>10.5897</td>\n",
       "      <td>8.62231</td>\n",
       "      <td>29.4473</td>\n",
       "      <td>27.0750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     flux_g    flux_i    flux_r     flux_u     flux_y  \\\n",
       "0    11567264019   40.96230   36.2869   37.3803   42.79600    58.9711   \n",
       "1    11690845043  357.10800  571.4560  471.1240  484.44300  1199.9800   \n",
       "2    11581148087   51.71180   64.1272   69.5459   22.81470    66.9363   \n",
       "3    11631115337   46.70340   42.7023   42.6977   48.35350    58.1880   \n",
       "4    11690275081  118.30800  373.8760  211.8320  120.56900   959.9060   \n",
       "..           ...        ...       ...       ...        ...        ...   \n",
       "795  11694913248   68.07290   74.1691   58.9424   50.73660    94.5738   \n",
       "796  11700048639   12.46040   13.9937   12.1656    6.85085    19.1662   \n",
       "797  11562625549   31.56970   96.4406   75.8143   11.79810   123.7010   \n",
       "798  11627559538  503.87300  942.4960  635.2230  588.65200  1740.1700   \n",
       "799  11565382553    8.78313   15.1979   10.5897    8.62231    29.4473   \n",
       "\n",
       "        flux_z  truth_type  \n",
       "0      40.2802           1  \n",
       "1    1002.8600           1  \n",
       "2      58.9267           1  \n",
       "3      42.2114           1  \n",
       "4     784.7030           1  \n",
       "..         ...         ...  \n",
       "795    86.5480           1  \n",
       "796    17.1776           1  \n",
       "797   111.2390           1  \n",
       "798  1526.6400           1  \n",
       "799    27.0750           1  \n",
       "\n",
       "[800 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2de21",
   "metadata": {},
   "source": [
    "### Part 1: Estimate Class Frequency in the training set\n",
    "\n",
    "One of the ingredients in our classifier is p(y), the unconditional class probabilities. \n",
    "\n",
    "We can get this by counting the number of rows belonging to each class in train_data and dividing by the length of the training data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0186b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_class_probabilities(data, class_column_name):\n",
    "    \"\"\"\n",
    "    Computes unconditional class probabilities. \n",
    "     \n",
    "    Args:\n",
    "        x_train (array): training data for the classifier\n",
    " \n",
    "    Returns:\n",
    "        ints p1, p2: unconditional probability of an element of the training set belonging to class 1\n",
    "    \"\"\"\n",
    "    \n",
    "    p1 = data.loc[data[class_column_name] == 1].shape[0]/data.shape[0]\n",
    "    p2 = data.loc[data[class_column_name] == 2].shape[0]/data.shape[0]\n",
    "\n",
    "    # print(data.loc[data[class_column_name] == 2].shape[0])\n",
    "    # print(data.loc[data[class_column_name] == 1].shape[0])\n",
    "    # print(data.shape[0])\n",
    "\n",
    "    return p1, p2\n",
    "\n",
    "p1, p2 = estimate_class_probabilities(train_data, 'truth_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35914e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82625, 0.17125)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1, p2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1aa268",
   "metadata": {},
   "source": [
    "### Part 2:  Feature Likelihoods\n",
    "\n",
    "We are assuming that the relationship between the classes and feature probabilities are related via:\n",
    "\n",
    "$p(x_i, ..., x_n | y) =  p(x_i|y)... p(x_n | y)$\n",
    "\n",
    "however, we still need to make an assumption about the functional form of the $p(x_i | y)$. As a simple case, we will assume $p(x_i | y)$ follows a Gaussian distribution given by:\n",
    "\n",
    "$$\n",
    "p(x_i | y) = \\frac{1}{\\sqrt{2 \\pi \\sigma_y}} \\exp{\\left(-\\frac{(x_i - \\mu)^2}{\\sigma_y^2}\\right)}\n",
    "$$\n",
    "\n",
    "and we will make a maximum likelihood estimate of $\\mu$ and $\\sigma_y$ from the data. This means using empirical estimates $\\bar{x}$ and $\\hat{\\sigma}$ as estimators of the true parameters $\\mu$ and $\\sigma_y$. \n",
    "\n",
    "Write a fitting function that takes the log of the fluxes and returns an estimate of the parameters of the per-feature likelihoods for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0d21ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_fluxes = ['flux_g','flux_i','flux_r','flux_u','flux_y','flux_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7877080f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flux_g    231500.334667\n",
       "flux_i    443167.480949\n",
       "flux_r    366335.958190\n",
       "flux_u     75500.916188\n",
       "flux_y    497683.143453\n",
       "flux_z    480758.377767\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_data[col_fluxes], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "609b65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_feature_likelihood_parameters(x_train, label):\n",
    "    \"\"\"\"\n",
    "    Computes MAP estimates for the class conditional likelihood. \n",
    "     \n",
    "    Args:\n",
    "        x_train (array or pd series): training data for the classifier\n",
    "        label (int): training labels for the classifier \n",
    " \n",
    "    Returns:\n",
    "        means, stdevs (array): MAP estimates of the Gaussian conditional probability distributions for a specific class\n",
    "    \"\"\"\n",
    "    \n",
    "    means = np.mean(np.log10(x_train[label]), axis=0)\n",
    "    stdevs = np.std(np.log10(x_train[label]), axis=0)\n",
    "    \n",
    "    return means, stdevs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "acfcbdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(x, mean, stdev):\n",
    "    \"\"\"\"\n",
    "    Computes the likelihood of a data point x under a Gaussian distribution with parameters mean and stdev. \n",
    "     \n",
    "    Args:\n",
    "        x (float): data point (assume already in log scale)\n",
    "        mean (float): mean of the Gaussian distribution\n",
    "        stdev (float): standard deviation of the Gaussian distribution\n",
    " \n",
    "    Returns:\n",
    "        likelihood (float): likelihood of x under the Gaussian distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    likelihood = norm.pdf(x, loc=mean, scale=stdev)\n",
    "    \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbeb61",
   "metadata": {},
   "source": [
    "### Part 3: MAP Estimates of the Class Probabilities\n",
    "\n",
    "Now that we have the unconditional class probabilities and the parameters of the per feature likelihoods in hand, we can put this all together to build the classifier. Use the methods you have already written to write a function that takes in the training data and returns fit parameters. Once you have done that, write a method that takes the fit parameters as an argument and predicts the class of new (and unseen) data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05a17f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the classifier\n",
    "\n",
    "# solved \n",
    "\n",
    "def fit(x_train):\n",
    "    \"\"\"\"\n",
    "    Convenience function to perform fitting on the training data\n",
    "     \n",
    "    Args:\n",
    "        x_train (array or pd series): training data for the classifier\n",
    " \n",
    "    Returns:\n",
    "        p1, p2, class_1_mean, class_2_mean, class_1_std, class_2_std: see documentation for per_feature_likelihood_parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute probabilities and MAP estimates of the Gaussian distribution's parameters using the methods you wrote above\n",
    "    p1, p2 = estimate_class_probabilities(x_train, 'truth_type')\n",
    "    class_1_mean, class_1_std = per_feature_likelihood_parameters(x_train.loc[x_train['truth_type']==1], col_fluxes)\n",
    "    class_2_mean, class_2_std = per_feature_likelihood_parameters(x_train.loc[x_train['truth_type']==2], col_fluxes)\n",
    "\n",
    "    return p1, p2, class_1_mean, class_2_mean, class_1_std, class_2_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70f72744",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2, class_1_mean, class_2_mean, class_1_std, class_2_std = fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01867cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(x_test, class_probability, class_means, class_dev, class_column_name):\n",
    "    \"\"\"\"\n",
    "    Predict method\n",
    "     \n",
    "    Args:\n",
    "        x_test (array): data to perform classification on\n",
    "        class_probability (array): unconditional class probabilities\n",
    "        class_means, class_dev (array): MAP estimates produced by the fit method\n",
    " \n",
    "    Returns:\n",
    "        predict_List (list): class membership predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute probabilities of an element of the test set belonging to class 1 or 2\n",
    "    predict_list = np.zeros(x_test.shape[0])\n",
    "\n",
    "    for i in range(x_test.shape[0]):\n",
    "        prior = class_probability\n",
    "        likelihoods = np.prod([likelihood(np.log10(x_test.loc[i,class_column_name[j]]), class_means[j], class_dev[j]) for j in range(len(class_means))])\n",
    "        posterior = prior*likelihoods\n",
    "        predict_list[i] = posterior\n",
    "    \n",
    "    \n",
    "    return predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1df3be5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.7118"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[2,col_fluxes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "20475a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_1 = predict(test_data, p1, class_1_mean, class_1_std, col_fluxes)\n",
    "prob_2 = predict(test_data, p2, class_2_mean, class_2_std, col_fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d46c82cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.33462875e-02, 6.48637360e-02, 3.42620654e-45, 3.13572561e-03,\n",
       "       1.72255723e-02, 1.31723109e-04, 2.04062289e-02, 6.08253901e-03,\n",
       "       3.22519981e-02, 1.23634640e-04, 7.78188814e-02, 1.53719053e-02,\n",
       "       2.42700412e-05, 8.98531611e-03, 3.51007984e-02, 2.34222232e-02,\n",
       "       3.77597547e-02, 3.67869375e-03, 3.18991338e-05, 1.77534305e-02,\n",
       "       7.69377689e-02, 4.22649095e-02, 2.01625444e-02, 2.04631835e-02,\n",
       "       2.93705536e-08, 2.67071984e-02, 6.22691924e-03, 2.62142686e-02,\n",
       "       5.13343166e-02, 3.97498661e-25, 2.83491454e-02, 5.64363286e-02,\n",
       "       5.84848479e-02, 5.92732083e-03, 3.44762951e-02, 5.84443922e-02,\n",
       "       9.58800149e-61, 1.07228104e-35, 5.80478079e-03, 6.48432473e-04,\n",
       "       8.16328917e-02, 4.40130355e-02, 2.63328477e-02, 6.92323586e-02,\n",
       "       1.07695274e-05, 4.31333528e-02, 2.16200437e-26, 6.39115292e-02,\n",
       "       2.21094483e-02, 2.64938384e-33, 5.57425910e-03, 6.88258673e-02,\n",
       "       4.06713556e-02, 5.17114205e-02, 4.26936014e-03, 2.38104621e-03,\n",
       "       4.36374763e-02, 6.93601203e-03, 3.04838988e-02, 5.54829828e-02,\n",
       "       6.74179467e-08, 7.77412514e-02, 2.00041194e-02, 3.01973471e-02,\n",
       "       4.08130159e-02, 4.10395111e-02, 4.86013047e-02, 1.29038116e-02,\n",
       "       5.15940376e-02, 1.85339423e-74, 5.80195640e-03, 3.74009881e-02,\n",
       "       2.64128526e-04, 1.51405033e-02, 1.93555458e-03, 5.02294471e-02,\n",
       "       4.36192166e-03, 1.49047624e-32, 1.29159154e-02, 2.71487964e-02,\n",
       "       2.14279565e-02, 2.03712366e-04, 3.74051293e-02, 5.05530654e-02,\n",
       "       1.16820655e-02, 2.15958432e-03, 2.36073400e-02, 6.04228983e-03,\n",
       "       1.33900987e-03, 7.25206757e-02, 2.14483564e-06, 1.08475512e-02,\n",
       "       2.96466479e-02, 4.06062087e-43, 1.28169788e-02, 4.03961477e-05,\n",
       "       5.94285197e-03, 6.12366957e-02, 3.33941314e-02, 5.43405072e-02,\n",
       "       4.81743157e-03, 2.50256904e-02, 5.75402492e-46, 5.05457180e-02,\n",
       "       3.37063892e-06, 6.31610424e-03, 3.93242895e-02, 8.63319497e-03,\n",
       "       5.60719267e-03, 3.53666480e-02, 6.63169396e-03, 4.44494906e-04,\n",
       "       1.63952981e-02, 1.92539855e-02, 7.40715642e-02, 4.63113590e-02,\n",
       "       3.22929931e-02, 5.32616902e-02, 1.39201112e-17, 3.15972588e-02,\n",
       "       1.33658432e-02, 2.68733331e-02, 5.25776295e-03, 2.63729035e-07,\n",
       "       1.01895053e-02, 6.72770667e-11, 4.52296076e-02, 2.22420006e-03,\n",
       "       1.88916959e-02, 1.79171189e-61, 7.55173935e-61, 2.34231398e-02,\n",
       "       1.77654008e-25, 6.50937985e-02, 7.70082257e-02, 3.58113915e-02,\n",
       "       1.99920939e-02, 6.66588163e-02, 2.00861239e-02, 6.67360011e-02,\n",
       "       1.67381063e-02, 7.80640079e-03, 3.71269899e-04, 2.43449561e-03,\n",
       "       4.36768803e-03, 8.77736482e-10, 5.33526929e-02, 4.71692034e-02,\n",
       "       2.13292967e-02, 5.83824275e-46, 6.14262857e-24, 5.03914000e-03,\n",
       "       1.76821755e-03, 1.43751637e-04, 2.07605920e-20, 5.87361937e-02,\n",
       "       6.42027731e-02, 1.15292004e-12, 1.54178877e-08, 1.98594425e-02,\n",
       "       3.67154420e-14, 2.13643017e-02, 6.19027663e-02, 8.39536577e-89,\n",
       "       4.40366731e-02, 1.16454208e-02, 1.00080535e-26, 2.60859294e-19,\n",
       "       4.90643422e-02, 2.16503303e-02, 6.24114792e-03, 5.85268800e-02,\n",
       "       4.33234118e-02, 4.21495634e-04, 4.55002437e-04, 6.12604226e-02,\n",
       "       6.13272390e-12, 1.04846346e-07, 4.45642506e-03, 5.36235123e-02,\n",
       "       7.01603028e-02, 8.24711815e-04, 6.21385813e-02, 5.22548206e-02,\n",
       "       6.12030070e-02, 6.88097834e-02, 1.76815353e-02, 4.24649187e-03,\n",
       "       4.99245142e-03, 6.16932464e-03, 8.63839323e-03, 4.07809408e-06,\n",
       "       1.21691913e-02, 6.80279042e-02, 8.38279311e-03, 1.20105851e-02,\n",
       "       8.97476716e-03, 2.66290002e-02, 9.65290024e-03, 1.71257119e-03])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "93a3c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = np.zeros(test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5192bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_data)):\n",
    "    if prob_1[i] > prob_2[i]:\n",
    "        predict_label[i] = 1\n",
    "    else:\n",
    "        predict_label[i] = 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8989e706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1.,\n",
       "       1., 1., 2., 2., 1., 1., 1., 1., 1., 1., 2., 1., 2., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 2., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 2., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       2., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2.,\n",
       "       1., 1., 1., 1., 2., 1., 2., 1., 1., 1., 2., 2., 1., 2., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 2., 2., 1., 1.,\n",
       "       1., 2., 1., 1., 2., 2., 1., 2., 1., 1., 2., 1., 1., 2., 2., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067d9e3",
   "metadata": {},
   "source": [
    "### Part 4: Metrics\n",
    "\n",
    "After creating a classifier, you now want to evaluate it in terms of how often it correctly and incorrectly classifies the objects in your training set. To do this, we'll design a confusion matrix. A confusion matrix is a matrix whose entries are the counts of the predicted vs actual class. For example, the first entry is the count of objects that are predicted to be of class 1 and actually are of class 1 and so on, while the off-diagonal elements would be instances of class 1 that are predicted to be of class 2, and instances of class 2 that are predicted to be of class 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a366c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(df_confusion, cmap=):\n",
    "    \"\"\"\n",
    "    \n",
    "    Convenience function to plot the confusion matrix from a pd.crosstab object. Hint: use plt.matshow and choose a sensible color map.\n",
    "    \n",
    "    Args:\n",
    "        df_confusion (pd.crosstab): A pd.crosstab object.\n",
    "        \n",
    "    Returns:\n",
    "        null \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    plt.matshow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c8763",
   "metadata": {},
   "source": [
    "## Problem 2: The Cramer-Rao bound (pen & paper, challenging, optional)\n",
    "\n",
    "As we saw in the lecture, the Cramer-Rao bound is an important result in statistics that has intuitive consequences for many applied problems in ML. The proof of the Cramer-Rao bound can be insightful to work through. \n",
    "\n",
    "The starting point for the proof of the bound is the Cauchy-Schwarz inequality, which can be used to show that:\n",
    "\n",
    "$$\n",
    "[Cov(U, V)]^2 \\le Var(U)Var(V)\n",
    "$$\n",
    "\n",
    "Starting from the definitions that U = T(X), where T(X) is an estimator of some parameter $\\theta$ of the distribution $f(X|\\theta)$ from which the data is sampled, and V = $\\frac{\\partial}{\\partial \\theta} log f(X |\\theta)$. Use the Cauchy-Schwarz inequality to show the Cramer-Rao bound for these choices of U and V. \n",
    "\n",
    "$\\textit{Hint:}$ you will need the fact that the $\\mathbb{E}(V) = 0$, where $\\mathbb{E}$ is the expectation of a random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1432f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
