{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75dba511",
   "metadata": {},
   "source": [
    "# Tutorial for Introduction to ML Lecture\n",
    "\n",
    "version 0.1, September 2023\n",
    "\n",
    "Bryan Scott, CIERA/Northwestern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c6b0f",
   "metadata": {},
   "source": [
    "## Problem 1: Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07842041",
   "metadata": {},
   "source": [
    "A good starting point for Machine Learning is the Bayes classifier. The basic idea is to assign the most probable label to each data point using Bayes theorem, we take:\n",
    "\n",
    "$$\n",
    "p(y | x_n) \\propto p(y)p(x_i, ..., x_n | y)\n",
    "$$\n",
    "\n",
    "where y is a label for a data point and the $x_n$ are the features of the data that we want to use to classify each data point. A $\\textit{Naive} Bayes$ classifier makes an important simplifying assumptions that gives it the name - it assumes that the conditional probabilities are independent, $p(x_i, ..., x_n | y) = p(x_i|y)... p(x_n | y)$. That is, the probability of observing any individual feature doesn't depend on any of the other features. Our task is to construct this classifier from a set of examples we've observed previously and compare it to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40084db8",
   "metadata": {},
   "source": [
    "### Part 0: Load and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1d0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11443882",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_data = pd.read_csv('session_19_extragalactic_subset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e543f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_data[0:1000].to_csv('session_19_DC2_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa6dd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsst_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c682ccc",
   "metadata": {},
   "source": [
    "### Loading and splitting the data. \n",
    "\n",
    "Read in the data, then start by selecting the id, fluxes, and object truth type in the lsst data file you've been provided. \n",
    "\n",
    "Once you have selected those, randomly split the data into two arrays, one containing 80% of the data, and a second array containing 20% of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94094b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_data = pd.read_csv('session_19_DC2_subset.csv') #path to your data\n",
    "\n",
    "col_to_classify = ['id','flux_g','flux_i','flux_r','flux_u','flux_y','flux_z','truth_type']\n",
    "\n",
    "lsst_data_to_classify = lsst_data.loc[:,col_to_classify]\n",
    "N_data_to_classify = lsst_data_to_classify.shape[0]\n",
    "random_data = np.sort(np.random.choice(N_data_to_classify, int(N_data_to_classify*0.2), replace=False))\n",
    "\n",
    "train_data = lsst_data_to_classify.drop(random_data)\n",
    "test_data = lsst_data_to_classify.loc[random_data].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccc9a1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9  17  28  42  44  50  51  54  62  64  70  82  92 104 110 112 114 118\n",
      " 120 132 135 139 140 154 157 159 162 164 165 166 167 179 186 195 197 221\n",
      " 225 226 228 230 234 236 243 244 247 253 254 255 262 289 292 301 302 307\n",
      " 308 322 323 329 339 346 363 364 366 372 375 385 387 388 392 394 397 399\n",
      " 402 411 413 414 417 419 428 429 434 436 454 462 463 472 477 478 479 483\n",
      " 484 487 495 498 505 510 519 522 523 524 526 529 531 538 540 541 546 549\n",
      " 557 572 580 582 584 593 594 596 599 601 608 610 614 617 620 629 631 636\n",
      " 642 650 660 663 669 676 679 682 684 685 687 691 695 708 711 719 726 766\n",
      " 767 771 773 786 791 793 798 799 800 803 804 806 811 815 819 825 827 830\n",
      " 849 851 852 853 857 858 867 876 878 881 890 894 897 898 902 904 908 910\n",
      " 913 915 927 931 933 935 937 944 946 949 955 956 976 978 981 984 988 990\n",
      " 997 998]\n"
     ]
    }
   ],
   "source": [
    "print(random_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bad63cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flux_g</th>\n",
       "      <th>flux_i</th>\n",
       "      <th>flux_r</th>\n",
       "      <th>flux_u</th>\n",
       "      <th>flux_y</th>\n",
       "      <th>flux_z</th>\n",
       "      <th>truth_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40969793594</td>\n",
       "      <td>17.83660</td>\n",
       "      <td>190.3410</td>\n",
       "      <td>51.4846</td>\n",
       "      <td>1.75680</td>\n",
       "      <td>422.2170</td>\n",
       "      <td>328.8920</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40969784981</td>\n",
       "      <td>9.22705</td>\n",
       "      <td>73.9039</td>\n",
       "      <td>27.5084</td>\n",
       "      <td>1.01195</td>\n",
       "      <td>140.4130</td>\n",
       "      <td>114.2860</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40969794479</td>\n",
       "      <td>12.76260</td>\n",
       "      <td>221.4810</td>\n",
       "      <td>44.3510</td>\n",
       "      <td>1.59968</td>\n",
       "      <td>817.0840</td>\n",
       "      <td>486.3460</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40969800379</td>\n",
       "      <td>52.11700</td>\n",
       "      <td>902.9370</td>\n",
       "      <td>180.9370</td>\n",
       "      <td>6.54124</td>\n",
       "      <td>3328.5400</td>\n",
       "      <td>1981.8000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41021116967</td>\n",
       "      <td>33.44870</td>\n",
       "      <td>57.3507</td>\n",
       "      <td>49.3317</td>\n",
       "      <td>12.15540</td>\n",
       "      <td>61.9937</td>\n",
       "      <td>60.5627</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>40047153469</td>\n",
       "      <td>3467.59000</td>\n",
       "      <td>27791.0000</td>\n",
       "      <td>10341.6000</td>\n",
       "      <td>380.10700</td>\n",
       "      <td>52816.9000</td>\n",
       "      <td>42984.4000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>40969624595</td>\n",
       "      <td>9.53608</td>\n",
       "      <td>67.9682</td>\n",
       "      <td>28.6144</td>\n",
       "      <td>1.09289</td>\n",
       "      <td>121.3620</td>\n",
       "      <td>100.3890</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>40969636266</td>\n",
       "      <td>29.97310</td>\n",
       "      <td>274.1900</td>\n",
       "      <td>89.0342</td>\n",
       "      <td>3.17704</td>\n",
       "      <td>559.9740</td>\n",
       "      <td>446.7240</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>40969635236</td>\n",
       "      <td>19.47590</td>\n",
       "      <td>129.9370</td>\n",
       "      <td>60.3894</td>\n",
       "      <td>2.10310</td>\n",
       "      <td>219.0790</td>\n",
       "      <td>184.0700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>40745628848</td>\n",
       "      <td>157.26200</td>\n",
       "      <td>1967.8800</td>\n",
       "      <td>440.7570</td>\n",
       "      <td>15.07460</td>\n",
       "      <td>4773.6800</td>\n",
       "      <td>3621.5700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id      flux_g      flux_i      flux_r     flux_u      flux_y  \\\n",
       "0    40969793594    17.83660    190.3410     51.4846    1.75680    422.2170   \n",
       "1    40969784981     9.22705     73.9039     27.5084    1.01195    140.4130   \n",
       "2    40969794479    12.76260    221.4810     44.3510    1.59968    817.0840   \n",
       "3    40969800379    52.11700    902.9370    180.9370    6.54124   3328.5400   \n",
       "4    41021116967    33.44870     57.3507     49.3317   12.15540     61.9937   \n",
       "..           ...         ...         ...         ...        ...         ...   \n",
       "195  40047153469  3467.59000  27791.0000  10341.6000  380.10700  52816.9000   \n",
       "196  40969624595     9.53608     67.9682     28.6144    1.09289    121.3620   \n",
       "197  40969636266    29.97310    274.1900     89.0342    3.17704    559.9740   \n",
       "198  40969635236    19.47590    129.9370     60.3894    2.10310    219.0790   \n",
       "199  40745628848   157.26200   1967.8800    440.7570   15.07460   4773.6800   \n",
       "\n",
       "         flux_z  truth_type  \n",
       "0      328.8920           2  \n",
       "1      114.2860           2  \n",
       "2      486.3460           2  \n",
       "3     1981.8000           2  \n",
       "4       60.5627           2  \n",
       "..          ...         ...  \n",
       "195  42984.4000           2  \n",
       "196    100.3890           2  \n",
       "197    446.7240           2  \n",
       "198    184.0700           2  \n",
       "199   3621.5700           2  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca3c49af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flux_g</th>\n",
       "      <th>flux_i</th>\n",
       "      <th>flux_r</th>\n",
       "      <th>flux_u</th>\n",
       "      <th>flux_y</th>\n",
       "      <th>flux_z</th>\n",
       "      <th>truth_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40749426052</td>\n",
       "      <td>589.69000</td>\n",
       "      <td>7390.7700</td>\n",
       "      <td>1654.2300</td>\n",
       "      <td>56.45420</td>\n",
       "      <td>17941.500</td>\n",
       "      <td>13607.600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40969792214</td>\n",
       "      <td>46.01050</td>\n",
       "      <td>328.2330</td>\n",
       "      <td>138.1330</td>\n",
       "      <td>5.26928</td>\n",
       "      <td>586.331</td>\n",
       "      <td>484.929</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40749426351</td>\n",
       "      <td>209.17300</td>\n",
       "      <td>2232.3500</td>\n",
       "      <td>603.7970</td>\n",
       "      <td>20.60080</td>\n",
       "      <td>4952.030</td>\n",
       "      <td>3857.390</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40969791100</td>\n",
       "      <td>2729.48000</td>\n",
       "      <td>4716.7300</td>\n",
       "      <td>4090.1800</td>\n",
       "      <td>1051.78000</td>\n",
       "      <td>5011.580</td>\n",
       "      <td>4917.180</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40969810898</td>\n",
       "      <td>9.54055</td>\n",
       "      <td>76.4186</td>\n",
       "      <td>28.4438</td>\n",
       "      <td>1.04629</td>\n",
       "      <td>145.195</td>\n",
       "      <td>118.177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>40969637437</td>\n",
       "      <td>188.09400</td>\n",
       "      <td>1716.6500</td>\n",
       "      <td>557.9820</td>\n",
       "      <td>19.97450</td>\n",
       "      <td>3502.080</td>\n",
       "      <td>2794.960</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>40969622675</td>\n",
       "      <td>1429.32000</td>\n",
       "      <td>11451.0000</td>\n",
       "      <td>4261.8200</td>\n",
       "      <td>156.72600</td>\n",
       "      <td>21758.800</td>\n",
       "      <td>17709.300</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>40969632587</td>\n",
       "      <td>55.82410</td>\n",
       "      <td>397.1930</td>\n",
       "      <td>167.3400</td>\n",
       "      <td>6.40664</td>\n",
       "      <td>708.629</td>\n",
       "      <td>586.350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>40034381371</td>\n",
       "      <td>70087.20000</td>\n",
       "      <td>640120.0000</td>\n",
       "      <td>208000.0000</td>\n",
       "      <td>7438.53000</td>\n",
       "      <td>1306330.000</td>\n",
       "      <td>1042430.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>40555696945</td>\n",
       "      <td>1505.36000</td>\n",
       "      <td>13749.8000</td>\n",
       "      <td>4467.7100</td>\n",
       "      <td>159.75800</td>\n",
       "      <td>28061.000</td>\n",
       "      <td>22391.900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       flux_g       flux_i       flux_r      flux_u  \\\n",
       "0    40749426052    589.69000    7390.7700    1654.2300    56.45420   \n",
       "1    40969792214     46.01050     328.2330     138.1330     5.26928   \n",
       "2    40749426351    209.17300    2232.3500     603.7970    20.60080   \n",
       "4    40969791100   2729.48000    4716.7300    4090.1800  1051.78000   \n",
       "5    40969810898      9.54055      76.4186      28.4438     1.04629   \n",
       "..           ...          ...          ...          ...         ...   \n",
       "995  40969637437    188.09400    1716.6500     557.9820    19.97450   \n",
       "996  40969622675   1429.32000   11451.0000    4261.8200   156.72600   \n",
       "997  40969632587     55.82410     397.1930     167.3400     6.40664   \n",
       "998  40034381371  70087.20000  640120.0000  208000.0000  7438.53000   \n",
       "999  40555696945   1505.36000   13749.8000    4467.7100   159.75800   \n",
       "\n",
       "          flux_y       flux_z  truth_type  \n",
       "0      17941.500    13607.600           2  \n",
       "1        586.331      484.929           2  \n",
       "2       4952.030     3857.390           2  \n",
       "4       5011.580     4917.180           2  \n",
       "5        145.195      118.177           2  \n",
       "..           ...          ...         ...  \n",
       "995     3502.080     2794.960           2  \n",
       "996    21758.800    17709.300           2  \n",
       "997      708.629      586.350           2  \n",
       "998  1306330.000  1042430.000           2  \n",
       "999    28061.000    22391.900           2  \n",
       "\n",
       "[800 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2de21",
   "metadata": {},
   "source": [
    "### Part 1: Estimate Class Frequency in the training set\n",
    "\n",
    "One of the ingredients in our classifier is p(y), the unconditional class probabilities. \n",
    "\n",
    "We can get this by counting the number of rows belonging to each class in train_data and dividing by the length of the training data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0186b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792\n",
      "0\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "def estimate_class_probabilities(data, class_column_name):\n",
    "    \"\"\"\n",
    "    Computes unconditional class probabilities. \n",
    "     \n",
    "    Args:\n",
    "        x_train (array): training data for the classifier\n",
    " \n",
    "    Returns:\n",
    "        ints p1, p2: unconditional probability of an element of the training set belonging to class 1\n",
    "    \"\"\"\n",
    "    \n",
    "    p1 = data.loc[data[class_column_name] == 1].shape[0]/data.shape[0]\n",
    "    p2 = data.loc[data[class_column_name] == 2].shape[0]/data.shape[0]\n",
    "\n",
    "    print(data.loc[data[class_column_name] == 2].shape[0])\n",
    "    print(data.loc[data[class_column_name] == 1].shape[0])\n",
    "    print(data.shape[0])\n",
    "\n",
    "    return p1, p2\n",
    "\n",
    "p1, p2 = estimate_class_probabilities(train_data, 'truth_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35914e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.99)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1, p2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1aa268",
   "metadata": {},
   "source": [
    "### Part 2:  Feature Likelihoods\n",
    "\n",
    "We are assuming that the relationship between the classes and feature probabilities are related via:\n",
    "\n",
    "$p(x_i, ..., x_n | y) =  p(x_i|y)... p(x_n | y)$\n",
    "\n",
    "however, we still need to make an assumption about the functional form of the $p(x_i | y)$. As a simple case, we will assume $p(x_i | y)$ follows a Gaussian distribution given by:\n",
    "\n",
    "$$\n",
    "p(x_i | y) = \\frac{1}{\\sqrt{2 \\pi \\sigma_y}} \\exp{\\left(-\\frac{(x_i - \\mu)^2}{\\sigma_y^2}\\right)}\n",
    "$$\n",
    "\n",
    "and we will make a maximum likelihood estimate of $\\mu$ and $\\sigma_y$ from the data. This means using empirical estimates $\\bar{x}$ and $\\hat{\\sigma}$ as estimators of the true parameters $\\mu$ and $\\sigma_y$. \n",
    "\n",
    "Write a fitting function that takes the log of the fluxes and returns an estimate of the parameters of the per-feature likelihoods for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "609b65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_feature_likelihood_parameters(x_train, label):\n",
    "    \"\"\"\"\n",
    "    Computes MAP estimates for the class conditional likelihood. \n",
    "     \n",
    "    Args:\n",
    "        x_train (array or pd series): training data for the classifier\n",
    "        label (int): training labels for the classifier \n",
    " \n",
    "    Returns:\n",
    "        means, stdevs (array): MAP estimates of the Gaussian conditional probability distributions for a specific class\n",
    "    \"\"\"\n",
    "    \n",
    "    means = \n",
    "    stdevs = \n",
    "    \n",
    "    return means, stdevs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbeb61",
   "metadata": {},
   "source": [
    "### Part 3: MAP Estimates of the Class Probabilities\n",
    "\n",
    "Now that we have the unconditional class probabilities and the parameters of the per feature likelihoods in hand, we can put this all together to build the classifier. Use the methods you have already written to write a function that takes in the training data and returns fit parameters. Once you have done that, write a method that takes the fit parameters as an argument and predicts the class of new (and unseen) data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05a17f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the classifier\n",
    "\n",
    "# solved \n",
    "\n",
    "def fit(x_train):\n",
    "    \"\"\"\"\n",
    "    Convenience function to perform fitting on the training data\n",
    "     \n",
    "    Args:\n",
    "        x_train (array or pd series): training data for the classifier\n",
    " \n",
    "    Returns:\n",
    "        p1, p2, class_1_mean, class_2_mean, class_1_std, class_2_std: see documentation for per_feature_likelihood_parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute probabilities and MAP estimates of the Gaussian distribution's parameters using the methods you wrote above\n",
    "    \n",
    "    return p1, p2, class_1_mean, class_2_mean, class_1_std, class_2_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01867cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(x_test, class_probability, class_means, class_dev):\n",
    "    \"\"\"\"\n",
    "    Predict method\n",
    "     \n",
    "    Args:\n",
    "        x_test (array): data to perform classification on\n",
    "        class_probability (array): unconditional class probabilities\n",
    "        class_means, class_dev (array): MAP estimates produced by the fit method\n",
    " \n",
    "    Returns:\n",
    "        predict_List (list): class membership predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute probabilities of an element of the test set belonging to class 1 or 2\n",
    "        \n",
    "    for i in range():\n",
    "        if \n",
    "            \n",
    "        if \n",
    "    \n",
    "    return predict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067d9e3",
   "metadata": {},
   "source": [
    "### Part 4: Metrics\n",
    "\n",
    "After creating a classifier, you now want to evaluate it in terms of how often it correctly and incorrectly classifies the objects in your training set. To do this, we'll design a confusion matrix. A confusion matrix is a matrix whose entries are the counts of the predicted vs actual class. For example, the first entry is the count of objects that are predicted to be of class 1 and actually are of class 1 and so on, while the off-diagonal elements would be instances of class 1 that are predicted to be of class 2, and instances of class 2 that are predicted to be of class 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a366c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(df_confusion, cmap=):\n",
    "    \"\"\"\n",
    "    \n",
    "    Convenience function to plot the confusion matrix from a pd.crosstab object. Hint: use plt.matshow and choose a sensible color map.\n",
    "    \n",
    "    Args:\n",
    "        df_confusion (pd.crosstab): A pd.crosstab object.\n",
    "        \n",
    "    Returns:\n",
    "        null \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    plt.matshow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c8763",
   "metadata": {},
   "source": [
    "## Problem 2: The Cramer-Rao bound (pen & paper, challenging, optional)\n",
    "\n",
    "As we saw in the lecture, the Cramer-Rao bound is an important result in statistics that has intuitive consequences for many applied problems in ML. The proof of the Cramer-Rao bound can be insightful to work through. \n",
    "\n",
    "The starting point for the proof of the bound is the Cauchy-Schwarz inequality, which can be used to show that:\n",
    "\n",
    "$$\n",
    "[Cov(U, V)]^2 \\le Var(U)Var(V)\n",
    "$$\n",
    "\n",
    "Starting from the definitions that U = T(X), where T(X) is an estimator of some parameter $\\theta$ of the distribution $f(X|\\theta)$ from which the data is sampled, and V = $\\frac{\\partial}{\\partial \\theta} log f(X |\\theta)$. Use the Cauchy-Schwarz inequality to show the Cramer-Rao bound for these choices of U and V. \n",
    "\n",
    "$\\textit{Hint:}$ you will need the fact that the $\\mathbb{E}(V) = 0$, where $\\mathbb{E}$ is the expectation of a random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1432f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
